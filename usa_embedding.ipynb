{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('capitals.csv', skiprows=[2,9])\n",
    "df = pd.read_csv('capitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_triplet(n):\n",
    "    head = np.random.randint(0,n)\n",
    "    \n",
    "    left = np.random.randint(0,n)\n",
    "    while left == head:\n",
    "        left = np.random.randint(0,n)\n",
    "        \n",
    "    right = np.random.randint(0,n)\n",
    "    while right == left or right == head:\n",
    "        right = np.random.randint(0,n)\n",
    "        \n",
    "    return [head, left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montana\n",
      "Michigan\n",
      "Iowa\n",
      "[23, 19, 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet = generate_random_triplet(len(df))\n",
    "print(df['name'][triplet[0]])\n",
    "print(df['name'][triplet[1]])\n",
    "print(df['name'][triplet[2]])\n",
    "print(triplet)\n",
    "get_comparison(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comparison(triplet):\n",
    "    head = (df['latitude'][triplet[0]], df['longitude'][triplet[0]])\n",
    "    left = (df['latitude'][triplet[1]], df['longitude'][triplet[1]])\n",
    "    right = (df['latitude'][triplet[2]], df['longitude'][triplet[2]])\n",
    "    return geodesic(head, left).miles < geodesic(head, right).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_true_embedding(df):\n",
    "    X = np.zeros([len(df),2])\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        X[i,0] = df['latitude'][i]\n",
    "        X[i,1] = df['longitude'][i]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(sample_size, num_points, df):\n",
    "    '''\n",
    "    Generate triplet data\n",
    "    '''\n",
    "    # X real embedding\n",
    "    triplets = []\n",
    "    labels = []\n",
    "    for _ in range(sample_size):\n",
    "        triplet = generate_random_triplet(num_points)\n",
    "        triplets.append(triplet)\n",
    "        if get_comparison(triplet):\n",
    "            labels.append([0,1])\n",
    "        else:\n",
    "            labels.append([1,0])\n",
    "\n",
    "    return get_true_embedding(df), {'samples': triplets, 'labels':labels}, \n",
    "\n",
    "def generate_samples(sample_size, num_points, df):\n",
    "    '''\n",
    "    Generate triplet data\n",
    "    '''\n",
    "    # X real embedding\n",
    "    triplets = []\n",
    "    labels = []\n",
    "    for i in range(num_points):\n",
    "        print(i)\n",
    "        for j in range(num_points):\n",
    "            for k in range(num_points):\n",
    "                if i!=j and i!=k and j!=k:\n",
    "                    q = [i , j, k]\n",
    "                    if get_comparison(q):\n",
    "                        labels.append([0,1])\n",
    "                    else:\n",
    "                        labels.append([1,0])\n",
    "                    triplets.append(q)\n",
    "    random_indices = np.random.choice(int(num_points*(num_points-1)*(num_points-2)/2), sample_size, replace=False)\n",
    "    return get_true_embedding(df), {'samples': [triplets[i] for i in random_indices], 'labels':[labels[i] for i in random_indices]}, {'samples': triplets, 'labels':labels}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def procrustes(X, Y, scaling=True, reflection='best'):\n",
    "    n = X.shape[0]; m = X.shape[1]\n",
    "    ny = Y.shape[0]; my = Y.shape[1]\n",
    "    muX = X.mean(0); muY = Y.mean(0)\n",
    "    X0 = X - muX; Y0 = Y - muY\n",
    "    ssX = (X0**2.).sum(); ssY = (Y0**2.).sum()\n",
    "    normX = np.sqrt(ssX); normY = np.sqrt(ssY)\n",
    "    X0 /= normX; Y0 /= normY\n",
    "    if my < m:\n",
    "        Y0 = np.concatenate((Y0, np.zeros(n, m-my)),0)\n",
    "    A = np.dot(X0.T, Y0)\n",
    "    U,s,Vt = np.linalg.svd(A,full_matrices=False)\n",
    "    V = Vt.T\n",
    "    T = np.dot(V, U.T)\n",
    "    if reflection is not 'best':\n",
    "        have_reflection = np.linalg.det(T) < 0\n",
    "        if reflection != have_reflection:\n",
    "            V[:,-1] *= -1\n",
    "            s[-1] *= -1\n",
    "            T = np.dot(V, U.T)\n",
    "    traceTA = s.sum()\n",
    "    if scaling:\n",
    "        b = traceTA * normX / normY\n",
    "        d = 1 - traceTA**2\n",
    "        Z = normX*traceTA*np.dot(Y0, T) + muX\n",
    "    else:\n",
    "        b = 1\n",
    "        d = 1 + ssY/ssX - 2 * traceTA * normY / normX\n",
    "        Z = normY*np.dot(Y0, T) + muX\n",
    "    if my < m:\n",
    "        T = T[:my,:]\n",
    "    c = muX - b*np.dot(muY, T)\n",
    "    tform = {'rotation':T, 'scale':b, 'translation':c}\n",
    "    return d, Z, tform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_embedding(df, sample_size, n, decay_rate, initial_scale, initial_step, batch_size):\n",
    "    decay = str(decay_rate)\n",
    "    items = str(n)\n",
    "    init_scale = str(initial_scale)\n",
    "    init_step = str(initial_step)\n",
    "\n",
    "    data = []\n",
    "    d=2\n",
    "    # Build the triples\n",
    "    X, train, entire = generate_samples(sample_size, n, df)\n",
    "\n",
    "    print('num constraints', len(train['samples']))\n",
    "    train_size = len(train['samples'])\n",
    "\n",
    "    # Build the Triplet Net\n",
    "    # W - rows of W will be our learned embedding\n",
    "    W = tf.Variable(tf.random_normal([n, d], 0., initial_scale), name=\"weights\")\n",
    "    head = tf.placeholder(tf.float32, [None, n])\n",
    "    left = tf.placeholder(tf.float32, [None, n])\n",
    "    right = tf.placeholder(tf.float32, [None, n])\n",
    "    y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "    # Computes |W*e_i - W*e_j|^2\n",
    "    dleft = tf.pow(tf.norm(tf.subtract(tf.matmul(head,W), tf.matmul(left, W)), axis=1), 2.)\n",
    "    # Computes |W*e_i - W*e_k|^2\n",
    "    dright = tf.pow(tf.norm(tf.subtract(tf.matmul(head,W), tf.matmul(right, W)), axis=1), 2.)\n",
    "\n",
    "    # Hinge loss variant\n",
    "    p = tf.stack([dleft-dright, dright-dleft], axis=1)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.maximum(0., 1.-tf.reduce_sum(y*p, reduction_indices=[1])))#tf.losses.hinge_loss(y, p)\n",
    "\n",
    "    I = np.eye(n,n)\n",
    "    head_data = [I[q[0], :] for q in train['samples']]\n",
    "    left_data = [I[q[1], :] for q in train['samples']]\n",
    "    right_data = [I[q[2], :] for q in train['samples']]\n",
    "    \n",
    "    head_data_entire = [I[q[0], :] for q in entire['samples']]\n",
    "    left_data_entire = [I[q[1], :] for q in entire['samples']]\n",
    "    right_data_entire = [I[q[2], :] for q in entire['samples']]\n",
    "\n",
    "    #shuffle the data\n",
    "    indices = np.random.permutation(train_size)\n",
    "\n",
    "    # For debugging purposes\n",
    "    #from tensorflow.python import debug as tf_debug\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Setup the optimizer and pass in the loss function/all the data batched in sets of 100 for SGD\n",
    "    global_step = tf.Variable(1.0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(initial_step, global_step, len(head_data), decay_rate)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    var_grad = tf.gradients(loss, W)[0]\n",
    "\n",
    "    # Compute training/test loss\n",
    "    correct_prediction = tf.equal(tf.argmax(p,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    initials = sess.run([W, loss, y*p, 1.-tf.reduce_sum(y*p, reduction_indices=[1])],feed_dict={head: head_data,\n",
    "                                                              left: left_data,\n",
    "                                                              right: right_data,\n",
    "                                                      y: train['labels']})\n",
    "    Winitial = initials[0]\n",
    "    start = time.time()\n",
    "    iteration = 0\n",
    "    old_loss = 0\n",
    "    \n",
    "    for _ in range(2000):\n",
    "        print('iter {}'.format(_))\n",
    "        x = sess.run([accuracy, loss, var_grad, learning_rate],\n",
    "                              feed_dict={head: head_data,\n",
    "                                         left: left_data,\n",
    "                                         right: right_data,\n",
    "                                         y: train['labels']})\n",
    "\n",
    "        print('accuracy', x[0], 'loss', x[1], 'gradient', np.linalg.norm(x[2],ord='fro'), 'learning_rate', x[3])\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        if x[0] == 1 or old_loss == x[1] :\n",
    "            break\n",
    "        old_loss = x[1]\n",
    "\n",
    "        for i in range(1, int(np.round(train_size/batch_size))):\n",
    "            if len(head_data[batch_size*(i-1): batch_size*i]) > 0:\n",
    "                sess.run([train_step],\n",
    "                          feed_dict={head: [head_data[j] for j in indices[batch_size*(i-1): batch_size*i]],\n",
    "                                     left: [left_data[j] for j in indices[batch_size*(i-1): batch_size*i]],\n",
    "                                     right: [right_data[j] for j in indices[batch_size*(i-1): batch_size*i]],\n",
    "                                     y: [train['labels'][j] for j in indices[batch_size*(i-1): batch_size*i]]})\n",
    "            else:\n",
    "                sess.run([train_step],\n",
    "                          feed_dict={head: [head_data[j] for j in indices[batch_size*(i-1):]],\n",
    "                                     left: [left_data[j] for j in indices[batch_size*(i-1): ]],\n",
    "                                     right: [right_data[j] for j in indices[batch_size*(i-1):]],\n",
    "                                     y: [train['labels'][j] for j in indices[batch_size*(i-1):]]})\n",
    "        indices = np.random.permutation(train_size)\n",
    "\n",
    "    result_test = sess.run([accuracy, W, loss,p], feed_dict={head: head_data,\n",
    "                                                     left: left_data,\n",
    "                                                     right: right_data,\n",
    "                                                     y: train['labels']})\n",
    "    \n",
    "    result_entire = sess.run([accuracy, W, loss,p], feed_dict={head: head_data_entire,\n",
    "                                                     left: left_data_entire,\n",
    "                                                     right: right_data_entire,\n",
    "                                                     y: entire['labels']})\n",
    "    end = time.time()\n",
    "    total_time=(end - start)\n",
    "\n",
    "    print('Final loss', result_test[2])\n",
    "    print('Accuracy on train set:', result_test[0], result_test[1])\n",
    "    print('Accuracy on entire data:', result_entire[0], result_entire[1])\n",
    "    min_gap = np.min(np.abs(result_test[3]))\n",
    "    print('min gap', min_gap)\n",
    "\n",
    "    #Procrustes and plot\n",
    "    if d==2:\n",
    "        W = result_test[1]\n",
    "        _, Wpro, _ = procrustes(X, W)\n",
    "#         plt.scatter(Wpro[:,0], Wpro[:,1])\n",
    "#         plt.scatter(X[:,0], X[:,1])\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            x = 10*X[i,1]\n",
    "            y = 10*X[i,0]\n",
    "            plt.plot(x, y, 'bo')\n",
    "            plt.text(x * (1 + 0.01), y * (1 + 0.01) , df['name'][i], fontsize=12)\n",
    "        plt.show()\n",
    "        for i in range(len(df)):\n",
    "            x = 10*Wpro[i,1]\n",
    "            y = 10*Wpro[i,0]\n",
    "            plt.plot(x, y, 'bo')\n",
    "            plt.text(x * (1 + 0.01), y * (1 + 0.01) , df['name'][i], fontsize=12)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        frob_error = np.linalg.norm(X-Wpro,'fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "num constraints 5000\n",
      "iter 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.5/site-packages/numpy/linalg/linalg.py:2176: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ret = sqrt(sqnorm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4926 loss 2.19236 gradient nan learning_rate 0.899567\n",
      "iter 1\n",
      "accuracy 0.8294 loss 0.690523 gradient nan learning_rate 0.556021\n",
      "iter 2\n",
      "accuracy 0.8932 loss 0.336481 gradient nan learning_rate 0.343676\n",
      "iter 3\n",
      "accuracy 0.9446 loss 0.174823 gradient 1.41421 learning_rate 0.212425\n",
      "iter 4\n",
      "accuracy 0.9624 loss 0.116595 gradient nan learning_rate 0.1313\n",
      "iter 5\n",
      "accuracy 0.98 loss 0.0680362 gradient nan learning_rate 0.0811562\n",
      "iter 6\n",
      "accuracy 0.9844 loss 0.0538571 gradient nan learning_rate 0.0501625\n",
      "iter 7\n",
      "accuracy 0.9894 loss 0.0432221 gradient 0.0 learning_rate 0.0310054\n",
      "iter 8\n",
      "accuracy 0.9936 loss 0.038419 gradient 1.41421 learning_rate 0.0191644\n",
      "iter 9\n",
      "accuracy 0.9932 loss 0.0355083 gradient 0.0 learning_rate 0.0118455\n",
      "iter 10\n",
      "accuracy 0.9934 loss 0.0339005 gradient 6.074e+09 learning_rate 0.00732167\n",
      "iter 11\n",
      "accuracy 0.994 loss 0.0336563 gradient nan learning_rate 0.00452551\n",
      "iter 12\n",
      "accuracy 0.9938 loss 0.0331261 gradient 3.29272e-10 learning_rate 0.00279721\n",
      "iter 13\n",
      "accuracy 0.994 loss 0.0329276 gradient 6.074e+09 learning_rate 0.00172895\n",
      "iter 14\n",
      "accuracy 0.994 loss 0.0328157 gradient 0.0 learning_rate 0.00106866\n",
      "iter 15\n",
      "accuracy 0.994 loss 0.0327519 gradient 0.0 learning_rate 0.000660539\n",
      "iter 16\n",
      "accuracy 0.994 loss 0.0327054 gradient 1.41421 learning_rate 0.000408278\n",
      "iter 17\n",
      "accuracy 0.994 loss 0.0326794 gradient nan learning_rate 0.000252356\n",
      "iter 18\n",
      "accuracy 0.994 loss 0.0326555 gradient 1.41421 learning_rate 0.000155981\n",
      "iter 19\n",
      "accuracy 0.994 loss 0.0326433 gradient 0.0 learning_rate 9.64115e-05\n",
      "iter 20\n",
      "accuracy 0.994 loss 0.032635 gradient 3.29272e-10 learning_rate 5.95918e-05\n",
      "iter 21\n",
      "accuracy 0.994 loss 0.0326307 gradient nan learning_rate 3.68336e-05\n",
      "iter 22\n",
      "accuracy 0.994 loss 0.0326285 gradient 0.0 learning_rate 2.27668e-05\n",
      "iter 23\n",
      "accuracy 0.994 loss 0.0326269 gradient 3.29272e-10 learning_rate 1.40721e-05\n",
      "iter 24\n",
      "accuracy 0.994 loss 0.0326259 gradient 0.0 learning_rate 8.69795e-06\n",
      "iter 25\n",
      "accuracy 0.994 loss 0.0326254 gradient 0.0 learning_rate 5.37619e-06\n",
      "iter 26\n",
      "accuracy 0.994 loss 0.032625 gradient 0.0 learning_rate 3.32301e-06\n",
      "iter 27\n",
      "accuracy 0.994 loss 0.0326248 gradient nan learning_rate 2.05395e-06\n"
     ]
    }
   ],
   "source": [
    "#find_embedding(df, sample_size, n, decay_rate, initial_scale, initial_step, batch_size)\n",
    "#find_embedding(df, 3000, 48, .09, 1, .9, 5)\n",
    "find_embedding(df, 5000, 50, .09, 1, .9, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>32.377716</td>\n",
       "      <td>-86.300568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>33.448143</td>\n",
       "      <td>-112.096962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>34.746613</td>\n",
       "      <td>-92.288986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>38.576668</td>\n",
       "      <td>-121.493629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>Denver</td>\n",
       "      <td>39.739227</td>\n",
       "      <td>-104.984856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>41.764046</td>\n",
       "      <td>-72.682198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Dover</td>\n",
       "      <td>39.157307</td>\n",
       "      <td>-75.519722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>30.438118</td>\n",
       "      <td>-84.281296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.749027</td>\n",
       "      <td>-84.388229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>Boise</td>\n",
       "      <td>43.617775</td>\n",
       "      <td>-116.199722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>39.798363</td>\n",
       "      <td>-89.654961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>39.768623</td>\n",
       "      <td>-86.162643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>41.591087</td>\n",
       "      <td>-93.603729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>Topeka</td>\n",
       "      <td>39.048191</td>\n",
       "      <td>-95.677956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Frankfort</td>\n",
       "      <td>38.186722</td>\n",
       "      <td>-84.875374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>30.457069</td>\n",
       "      <td>-91.187393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Maine</td>\n",
       "      <td>Augusta</td>\n",
       "      <td>44.307167</td>\n",
       "      <td>-69.781693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>38.978764</td>\n",
       "      <td>-76.490936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>42.358162</td>\n",
       "      <td>-71.063698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lansing</td>\n",
       "      <td>42.733635</td>\n",
       "      <td>-84.555328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>St. Paul</td>\n",
       "      <td>44.955097</td>\n",
       "      <td>-93.102211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>32.303848</td>\n",
       "      <td>-90.182106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>Jefferson City</td>\n",
       "      <td>38.579201</td>\n",
       "      <td>-92.172935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Montana</td>\n",
       "      <td>Helena</td>\n",
       "      <td>46.585709</td>\n",
       "      <td>-112.018417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>40.808075</td>\n",
       "      <td>-96.699654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>Carson City</td>\n",
       "      <td>39.163914</td>\n",
       "      <td>-119.766121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Concord</td>\n",
       "      <td>43.206898</td>\n",
       "      <td>-71.537994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>40.220596</td>\n",
       "      <td>-74.769913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Santa Fe</td>\n",
       "      <td>35.682240</td>\n",
       "      <td>-105.939728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>35.780430</td>\n",
       "      <td>-78.639099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>Bismarck</td>\n",
       "      <td>46.820850</td>\n",
       "      <td>-100.783318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>42.652843</td>\n",
       "      <td>-73.757874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>39.961346</td>\n",
       "      <td>-82.999069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>35.492207</td>\n",
       "      <td>-97.503342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>Salem</td>\n",
       "      <td>44.938461</td>\n",
       "      <td>-123.030403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>40.264378</td>\n",
       "      <td>-76.883598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Providence</td>\n",
       "      <td>41.830914</td>\n",
       "      <td>-71.414963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>34.000343</td>\n",
       "      <td>-81.033211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>44.367031</td>\n",
       "      <td>-100.346405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>36.165810</td>\n",
       "      <td>-86.784241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Austin</td>\n",
       "      <td>30.274670</td>\n",
       "      <td>-97.740349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Utah</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>40.777477</td>\n",
       "      <td>-111.888237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>Montpelier</td>\n",
       "      <td>44.262436</td>\n",
       "      <td>-72.580536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>37.538857</td>\n",
       "      <td>-77.433640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>47.035805</td>\n",
       "      <td>-122.905014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>38.336246</td>\n",
       "      <td>-81.612328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Madison</td>\n",
       "      <td>43.074684</td>\n",
       "      <td>-89.384445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>41.140259</td>\n",
       "      <td>-104.820236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name     description   latitude   longitude\n",
       "0          Alabama      Montgomery  32.377716  -86.300568\n",
       "1          Arizona         Phoenix  33.448143 -112.096962\n",
       "2         Arkansas     Little Rock  34.746613  -92.288986\n",
       "3       California      Sacramento  38.576668 -121.493629\n",
       "4         Colorado          Denver  39.739227 -104.984856\n",
       "5      Connecticut        Hartford  41.764046  -72.682198\n",
       "6         Delaware           Dover  39.157307  -75.519722\n",
       "7          Florida     Tallahassee  30.438118  -84.281296\n",
       "8          Georgia         Atlanta  33.749027  -84.388229\n",
       "9            Idaho           Boise  43.617775 -116.199722\n",
       "10        Illinois     Springfield  39.798363  -89.654961\n",
       "11         Indiana    Indianapolis  39.768623  -86.162643\n",
       "12            Iowa      Des Moines  41.591087  -93.603729\n",
       "13          Kansas          Topeka  39.048191  -95.677956\n",
       "14        Kentucky       Frankfort  38.186722  -84.875374\n",
       "15       Louisiana     Baton Rouge  30.457069  -91.187393\n",
       "16           Maine         Augusta  44.307167  -69.781693\n",
       "17        Maryland       Annapolis  38.978764  -76.490936\n",
       "18   Massachusetts          Boston  42.358162  -71.063698\n",
       "19        Michigan         Lansing  42.733635  -84.555328\n",
       "20       Minnesota        St. Paul  44.955097  -93.102211\n",
       "21     Mississippi         Jackson  32.303848  -90.182106\n",
       "22        Missouri  Jefferson City  38.579201  -92.172935\n",
       "23         Montana          Helena  46.585709 -112.018417\n",
       "24        Nebraska         Lincoln  40.808075  -96.699654\n",
       "25          Nevada     Carson City  39.163914 -119.766121\n",
       "26   New Hampshire         Concord  43.206898  -71.537994\n",
       "27      New Jersey         Trenton  40.220596  -74.769913\n",
       "28      New Mexico        Santa Fe  35.682240 -105.939728\n",
       "29  North Carolina         Raleigh  35.780430  -78.639099\n",
       "30    North Dakota        Bismarck  46.820850 -100.783318\n",
       "31        New York          Albany  42.652843  -73.757874\n",
       "32            Ohio        Columbus  39.961346  -82.999069\n",
       "33        Oklahoma   Oklahoma City  35.492207  -97.503342\n",
       "34          Oregon           Salem  44.938461 -123.030403\n",
       "35    Pennsylvania      Harrisburg  40.264378  -76.883598\n",
       "36    Rhode Island      Providence  41.830914  -71.414963\n",
       "37  South Carolina        Columbia  34.000343  -81.033211\n",
       "38    South Dakota          Pierre  44.367031 -100.346405\n",
       "39       Tennessee       Nashville  36.165810  -86.784241\n",
       "40           Texas          Austin  30.274670  -97.740349\n",
       "41            Utah  Salt Lake City  40.777477 -111.888237\n",
       "42         Vermont      Montpelier  44.262436  -72.580536\n",
       "43        Virginia        Richmond  37.538857  -77.433640\n",
       "44      Washington         Olympia  47.035805 -122.905014\n",
       "45   West Virginia      Charleston  38.336246  -81.612328\n",
       "46       Wisconsin         Madison  43.074684  -89.384445\n",
       "47         Wyoming        Cheyenne  41.140259 -104.820236"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
